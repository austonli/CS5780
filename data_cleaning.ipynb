{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the csv files\n",
    "train = pd.read_csv(\"train.csv\",header = None).values\n",
    "test = pd.read_csv(\"test.csv\",header = None).values\n",
    "#isRetweet,retweeted, screenName,favorited, truncated, replytoSN are all irrelevant\n",
    "#replyToSN, created, longitude, latitude,replytoUID is mostly NAs\n",
    "#statusSource is missing from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the unnecessary columns\n",
    "train_sel = train[:,[1,3,5,8,12,17]]\n",
    "test_sel = test[:,[1,3,5,8,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping NA values\n",
    "for i in train_sel:\n",
    "    for j in i:\n",
    "        if j == \"NA\":\n",
    "            j = 0\n",
    "            \n",
    "for i in test_sel:\n",
    "    for j in i:\n",
    "        if j == \"NA\":\n",
    "            j = 0\n",
    "\"NA\" in train_sel.any()\n",
    "\"NA\" in test_sel.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "train_word_count = ['chars'] #converting the tweets into character counts\n",
    "train_hash_count = ['#s'] #counting the number of hashtags\n",
    "train_link_count = ['isLink'] #how many links are in the tweet\n",
    "train_ats_count = ['atPerson'] #how many @s\n",
    "train_is_retweet = ['isRT'] #was this a retweet?\n",
    "for i in train_sel[1:,0]:\n",
    "    train_word_count.append(len(i))\n",
    "    train_hash_count.append(i.count(\"#\"))\n",
    "    train_link_count.append(i.count(\"https\"))\n",
    "    train_ats_count.append(i.count(\"@\"))\n",
    "    train_is_retweet.append(\"\\\"@\" in i)\n",
    "\n",
    "test_word_count = ['chars']\n",
    "test_hash_count = ['#s']\n",
    "test_link_count = ['isLink']\n",
    "test_ats_count = ['atPerson']\n",
    "test_is_retweet = ['isRT']\n",
    "\n",
    "for i in test_sel[1:,0]:\n",
    "    test_word_count.append(len(i))\n",
    "    test_hash_count.append(i.count(\"#\"))\n",
    "    test_link_count.append(i.count(\"https\"))\n",
    "    test_ats_count.append(i.count(\"@\"))\n",
    "    test_is_retweet.append(\"\\\"@\" in i)\n",
    "#converting the date times\n",
    "train_dt = []\n",
    "test_dt = []\n",
    "for i in train_sel[1:,2]:\n",
    "    train_dt.append(dt.datetime.strptime(i,'%m/%d/%Y %H:%M'))\n",
    "for i in test_sel[1:,2]:\n",
    "    test_dt.append(dt.datetime.strptime(i,'%m/%d/%Y %H:%M'))\n",
    "train_month = ['month']\n",
    "train_year = ['year']\n",
    "train_day = ['day']\n",
    "train_time = ['time']\n",
    "test_month = ['month']\n",
    "test_year = ['year']\n",
    "test_day = ['day']\n",
    "test_time = ['time']\n",
    "for i in train_dt:\n",
    "    train_month.append(i.month)\n",
    "    train_year.append(i.year)\n",
    "    train_day.append(i.isoweekday())\n",
    "    train_time.append((i.hour*60+i.minute+1800)%2400) #benchmarked time from time elapsed since 6am\n",
    "for i in test_dt:\n",
    "    test_month.append(i.month)\n",
    "    test_year.append(i.year)\n",
    "    test_day.append(i.isoweekday())\n",
    "    test_time.append((i.hour*60+i.minute+1800)%2400)\n",
    "train_features = [train_word_count,train_hash_count,train_link_count,train_ats_count,train_month,train_year,train_day,train_time,train_is_retweet]\n",
    "test_features = [test_word_count,test_hash_count,test_link_count,test_ats_count,test_month,test_year,test_day,test_time,test_is_retweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of #s\n",
    "#is there hyperlink in tweet\n",
    "#! points\n",
    "#tweets at people\n",
    "#tweets within an hour are probably the same label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining the data columns\n",
    "train_ft = np.append(train_sel[:,0:5],np.zeros((train.shape[0],9)),axis = 1) #combining new feature vectors\n",
    "train_ft[:,5:] = np.array([train_word_count,train_hash_count,train_link_count,train_ats_count,train_month,train_year,train_day,train_time,train_is_retweet]).T\n",
    "test_ft = np.append(test_sel,np.zeros((test.shape[0],9)),axis = 1)\n",
    "test_ft[:,5:] = np.array([test_word_count,test_hash_count,test_link_count,test_ats_count,test_month,test_year,test_day,test_time,test_is_retweet]).T\n",
    "lbls = train_sel[:,5]\n",
    "#train_ft = train_ft[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifying the day of week to weekday or weekend\n",
    "train_weekdays = np.add(np.where(train_ft[1:,11].astype(int) < 6),1)\n",
    "train_weekends = np.add(np.where(train_ft[1:,11].astype(int) >= 6),1)\n",
    "test_weekdays = np.add(np.where(test_ft[1:,11].astype(int) < 6),1)\n",
    "test_weekends = np.add(np.where(test_ft[1:,11].astype(int) >= 6),1)\n",
    "\n",
    "train_ft[train_weekdays,11] = 0\n",
    "train_ft[train_weekends,11] = 1\n",
    "test_ft[test_weekdays,11] = 0\n",
    "test_ft[test_weekends,11] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #package for csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,d = train_ft.shape #writing the modified data into new csv files\n",
    "with open('mod_train.csv', mode='w') as mod_train:\n",
    "    mod_train = csv.writer(mod_train, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n):\n",
    "        line = train_ft[i,:]\n",
    "        line = np.append(line,lbls[i])\n",
    "        mod_train.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,d = test_ft.shape\n",
    "with open('mod_test.csv', mode='w') as mod_test:\n",
    "    mod_test = csv.writer(mod_test, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in range(n):\n",
    "        mod_test.writerow(test_ft[i,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
